<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lec 10 LLM_v1.3 - Interactive Learning</title>
    
    <!-- KaTeX for formula rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    
    <!-- Chart.js for data visualization -->
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.4/dist/chart.umd.min.js"></script>
    
    <!-- Mermaid for flowcharts and diagrams -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.9.1/dist/mermaid.min.js"></script>
    
    <!-- Fonts: Noto Serif for body, Inter for headings -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;600;700&family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    
    <style>
        
        :root {
            /* Warm Academic Theme - Clean & Readable */
            --bg-primary: #1a1a2e;
            --bg-secondary: #16213e;
            --bg-tertiary: #1f2b47;
            --bg-elevated: #263352;
            --bg-card: #1c2a45;
            
            --text-primary: #edf2f7;
            --text-secondary: #a0aec0;
            --text-tertiary: #718096;
            
            /* Warm Gold + Sage Green palette */
            --accent-primary: #f6c177;
            --accent-secondary: #a3d9a5;
            --accent-tertiary: #c4b5fd;
            --accent-warning: #fbbf24;
            --accent-error: #fb7185;
            --accent-info: #7dd3fc;
            
            --gradient-primary: linear-gradient(135deg, #f6c177 0%, #e8a87c 100%);
            --gradient-heading: linear-gradient(135deg, #f6c177 0%, #c4b5fd 100%);
            
            --border-color: rgba(255, 255, 255, 0.06);
            --border-hover: rgba(246, 193, 119, 0.25);
            --shadow-sm: 0 1px 2px rgba(0, 0, 0, 0.25);
            --shadow-md: 0 4px 12px rgba(0, 0, 0, 0.3);
            --shadow-lg: 0 8px 24px rgba(0, 0, 0, 0.4);
            
            --font-body: 'Georgia', 'Times New Roman', 'Noto Serif SC', serif;
            --font-heading: -apple-system, 'Helvetica Neue', 'PingFang SC', sans-serif;
            --font-mono: 'SF Mono', 'Menlo', 'Monaco', monospace;
            
            --radius-sm: 8px;
            --radius-md: 12px;
            --radius-lg: 16px;
            
            --ease: cubic-bezier(0.4, 0, 0.2, 1);
        }
        
        @media (prefers-color-scheme: light) {
            :root {
                --bg-primary: #faf8f5;
                --bg-secondary: #f0ece4;
                --bg-tertiary: #e8e2d8;
                --bg-elevated: #ffffff;
                --bg-card: #ffffff;
                
                --text-primary: #1c1917;
                --text-secondary: #57534e;
                --text-tertiary: #a8a29e;
                
                --accent-primary: #c2742f;
                --accent-secondary: #3d8b40;
                --accent-tertiary: #7c3aed;
                --accent-warning: #b45309;
                --accent-error: #dc2626;
                
                --gradient-heading: linear-gradient(135deg, #c2742f 0%, #7c3aed 100%);
                
                --border-color: rgba(0, 0, 0, 0.06);
                --border-hover: rgba(194, 116, 47, 0.3);
                --shadow-sm: 0 1px 2px rgba(0, 0, 0, 0.06);
                --shadow-md: 0 4px 12px rgba(0, 0, 0, 0.08);
                --shadow-lg: 0 8px 24px rgba(0, 0, 0, 0.12);
            }
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        html {
            scroll-behavior: smooth;
            font-size: 16px;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }
        
        body {
            font-family: var(--font-body);
            background: var(--bg-primary);
            color: var(--text-primary);
            line-height: 1.8;
            overflow-x: hidden;
        }
        
        .page-container {
            --left-width: 260px;
            --right-width: 300px;
            display: grid;
            grid-template-columns: minmax(200px, var(--left-width)) 8px minmax(0, 1fr) 8px minmax(220px, var(--right-width));
            min-height: 100vh;
            position: relative;
            z-index: 1;
        }

        .column-resizer {
            cursor: col-resize;
            background: transparent;
            transition: background-color 0.15s var(--ease);
            position: sticky;
            top: 0;
            height: 100vh;
            z-index: 5;
        }
        .column-resizer:hover,
        .column-resizer.dragging {
            background: rgba(246, 193, 119, 0.2);
        }
        
        .sidebar-left, .sidebar-right {
            background: var(--bg-secondary);
            padding: 2rem 1.25rem;
            position: sticky;
            top: 0;
            height: 100vh;
            overflow-y: auto;
        }
        
        .sidebar-left {
            border-right: 1px solid var(--border-color);
        }
        
        .sidebar-right {
            border-left: 1px solid var(--border-color);
        }
        
        .main-content {
            max-width: none;
            min-width: 0;
            width: 100%;
            margin: 0 auto;
            padding: 3rem 2.5rem;
        }
        
        @media (max-width: 1200px) {
            .page-container { grid-template-columns: 1fr; }
            .sidebar-left, .sidebar-right, .column-resizer { display: none; }
            .main-content { padding: 2rem 1.25rem; }
        }
        
        h1 {
            font-family: var(--font-heading);
            font-size: clamp(1.875rem, 4vw, 2.5rem);
            font-weight: 700;
            line-height: 1.2;
            margin-bottom: 0.75rem;
            letter-spacing: -0.01em;
            color: var(--text-primary);
        }
        
        h2 {
            font-family: var(--font-heading);
            font-size: 1.5rem;
            font-weight: 600;
            margin-top: 3.5rem;
            margin-bottom: 1.25rem;
            color: var(--accent-primary);
            letter-spacing: -0.01em;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--border-color);
        }
        
        h3 {
            font-family: var(--font-heading);
            font-size: 1.2rem;
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: var(--text-primary);
        }
        
        h4 {
            font-family: var(--font-heading);
            font-size: 0.8rem;
            font-weight: 600;
            margin-bottom: 0.5rem;
            color: var(--accent-primary);
            text-transform: uppercase;
            letter-spacing: 0.08em;
        }
        
        h5 {
            font-size: 0.95rem;
            font-weight: 600;
            margin-bottom: 0.5rem;
        }
        
        p {
            margin-bottom: 1rem;
            color: var(--text-secondary);
            font-size: 1rem;
            line-height: 1.8;
        }
        
        .feynman-block {
            background: var(--bg-card);
            border: 1px solid var(--border-color);
            border-left: 3px solid var(--accent-primary);
            border-radius: var(--radius-md);
            padding: 1.5rem;
            margin: 1.5rem 0;
            transition: border-color 0.2s var(--ease);
        }
        
        .feynman-block:hover {
            border-color: var(--border-hover);
        }
        
        .feynman-block .icon {
            font-size: 1.75rem;
            margin-bottom: 0.75rem;
            display: inline-block;
        }
        
        .expandable {
            background: var(--bg-card);
            border: 1px solid var(--border-color);
            border-radius: var(--radius-md);
            margin: 1.5rem 0;
            overflow: hidden;
        }
        
        .expandable-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 1.25rem;
            cursor: pointer;
            user-select: none;
            font-weight: 500;
            font-family: var(--font-heading);
            transition: background 0.15s var(--ease);
        }
        
        .expandable-header:hover {
            background: var(--bg-tertiary);
        }
        
        .expandable-icon {
            transition: transform 0.25s var(--ease);
            display: inline-block;
            font-size: 0.8rem;
        }
        
        .expandable.open .expandable-icon {
            transform: rotate(180deg);
        }
        
        .expandable-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.4s var(--ease);
        }
        
        .expandable.open .expandable-content {
            max-height: 5000px;
        }
        
        .expandable-content-inner {
            padding: 1.25rem;
            border-top: 1px solid var(--border-color);
        }
        
        .quiz-container {
            background: var(--bg-card);
            border-radius: var(--radius-md);
            padding: 1.5rem;
            margin: 2rem 0;
            border: 1px solid var(--border-color);
        }
        
        .quiz-question {
            font-size: 1.05rem;
            font-family: var(--font-heading);
            margin-bottom: 1.25rem;
            color: var(--text-primary);
        }
        
        .quiz-options {
            display: flex;
            flex-direction: column;
            gap: 0.625rem;
        }
        
        .quiz-option {
            background: var(--bg-tertiary);
            border: 1px solid var(--border-color);
            border-radius: var(--radius-sm);
            padding: 0.75rem 1rem;
            cursor: pointer;
            transition: all 0.15s var(--ease);
            font-size: 0.95rem;
        }
        
        .quiz-option:hover {
            border-color: var(--accent-primary);
            padding-left: 1.25rem;
        }
        
        .quiz-option.correct {
            background: rgba(163, 217, 165, 0.2);
            border-color: var(--accent-secondary);
            color: var(--accent-secondary);
        }
        
        .quiz-option.incorrect {
            background: rgba(251, 113, 133, 0.15);
            border-color: var(--accent-error);
            color: var(--accent-error);
        }
        
        .quiz-feedback {
            margin-top: 1rem;
            padding: 0.75rem 1rem;
            border-radius: var(--radius-sm);
            display: none;
            font-size: 0.9rem;
        }
        
        .quiz-feedback.show { display: block; }
        .quiz-feedback.correct { background: rgba(163, 217, 165, 0.15); border: 1px solid var(--accent-secondary); }
        .quiz-feedback.incorrect { background: rgba(251, 113, 133, 0.1); border: 1px solid var(--accent-error); }
        
        .progress-tracker {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 3px;
            background: var(--bg-secondary);
            z-index: 1000;
        }
        
        .progress-bar {
            height: 100%;
            background: var(--gradient-primary);
            width: 0%;
            transition: width 0.2s var(--ease);
        }
        
        .ai-chat {
            background: var(--bg-card);
            border: 1px solid var(--border-color);
            border-radius: var(--radius-md);
            padding: 1.25rem;
        }
        
        .ai-chat-header {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            margin-bottom: 1rem;
            padding-bottom: 0.75rem;
            border-bottom: 1px solid var(--border-color);
        }
        
        .ai-chat-messages {
            max-height: 320px;
            overflow-y: auto;
            margin-bottom: 0.75rem;
            padding: 0.75rem;
            background: var(--bg-primary);
            border-radius: var(--radius-sm);
        }
        
        .ai-message {
            margin-bottom: 0.75rem;
            padding: 0.625rem 0.875rem;
            border-radius: var(--radius-sm);
            font-size: 0.875rem;
            line-height: 1.6;
        }
        
        .ai-message.user {
            background: var(--accent-primary);
            color: var(--bg-primary);
            margin-left: 1.5rem;
            font-weight: 500;
        }
        
        .ai-message.assistant {
            background: var(--bg-tertiary);
            margin-right: 1.5rem;
        }
        
        .ai-input-group { display: flex; gap: 0.5rem; }
        
        .ai-input {
            flex: 1;
            background: var(--bg-primary);
            border: 1px solid var(--border-color);
            border-radius: var(--radius-sm);
            padding: 0.625rem 0.75rem;
            color: var(--text-primary);
            font-family: var(--font-body);
            font-size: 0.875rem;
        }
        
        .ai-input:focus {
            outline: none;
            border-color: var(--accent-primary);
        }
        
        .ai-send-btn, .action-btn {
            background: var(--accent-primary);
            color: var(--bg-primary);
            border: none;
            border-radius: var(--radius-sm);
            padding: 0.625rem 1rem;
            cursor: pointer;
            font-weight: 600;
            font-family: var(--font-heading);
            font-size: 0.85rem;
            transition: opacity 0.15s;
        }
        
        .action-btn {
            width: 100%;
            margin-bottom: 0.5rem;
            text-align: left;
            background: var(--bg-tertiary);
            color: var(--text-secondary);
            border: 1px solid var(--border-color);
        }
        
        .ai-send-btn:hover { opacity: 0.85; }
        .action-btn:hover { border-color: var(--accent-primary); color: var(--accent-primary); }
        
        kbd {
            background: var(--bg-tertiary);
            border: 1px solid var(--border-color);
            border-radius: 4px;
            padding: 0.15rem 0.5rem;
            font-family: var(--font-mono);
            font-size: 0.8em;
        }
        
        .toc-link {
            color: var(--text-secondary);
            text-decoration: none;
            display: block;
            padding: 0.375rem 0.5rem;
            border-radius: var(--radius-sm);
            font-size: 0.875rem;
            font-family: var(--font-heading);
            transition: color 0.15s, background 0.15s;
        }
        
        .toc-link:hover {
            color: var(--accent-primary);
            background: var(--bg-tertiary);
        }
        
        /* Scroll reveal - simple fade */
        .reveal-on-scroll {
            opacity: 0;
            transform: translateY(16px);
            transition: opacity 0.5s var(--ease), transform 0.5s var(--ease);
        }
        .reveal-on-scroll.revealed {
            opacity: 1;
            transform: translateY(0);
        }
        
        /* Scrollbar */
        ::-webkit-scrollbar { width: 8px; }
        ::-webkit-scrollbar-track { background: transparent; }
        ::-webkit-scrollbar-thumb { background: var(--bg-elevated); border-radius: 4px; }
        ::-webkit-scrollbar-thumb:hover { background: var(--text-tertiary); }
        
        ::selection { background: var(--accent-primary); color: var(--bg-primary); }
        
        /* Print */
        @media print {
            .sidebar-left, .sidebar-right, .progress-tracker { display: none; }
            .page-container { grid-template-columns: 1fr; }
            body { background: white; color: black; }
        }
        
        /* ===========================================
           DATA VISUALIZATION & CHARTS
           =========================================== */
        .chart-container {
            background: var(--bg-card);
            border-radius: var(--radius-md);
            padding: 1.5rem;
            margin: 2rem 0;
            box-shadow: var(--shadow-sm);
            border: 1px solid var(--border-color);
        }
        .chart-container .chart-title {
            font-family: var(--font-heading);
            font-size: 1.05rem;
            font-weight: 600;
            color: var(--text-primary);
            margin-bottom: 0.75rem;
            text-align: center;
        }
        .chart-container canvas { max-height: 380px; width: 100% !important; }
        .chart-caption {
            font-size: 0.85rem;
            color: var(--text-tertiary);
            text-align: center;
            margin-top: 0.75rem;
            font-style: italic;
        }
        .chart-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
            gap: 1.5rem;
            margin: 2rem 0;
        }
        .chart-grid .chart-container { margin: 0; }
        
        .diagram-container {
            background: var(--bg-card);
            border-radius: var(--radius-md);
            padding: 1.5rem;
            margin: 2rem 0;
            box-shadow: var(--shadow-sm);
            border: 1px solid var(--border-color);
            overflow-x: auto;
            text-align: center;
        }
        .diagram-container .diagram-title {
            font-family: var(--font-heading);
            font-size: 1.05rem;
            font-weight: 600;
            color: var(--text-primary);
            margin-bottom: 0.75rem;
        }
        .diagram-container .mermaid { display: flex; justify-content: center; }
        .diagram-container .mermaid svg { max-width: 100%; height: auto; }
        .diagram-caption {
            font-size: 0.85rem;
            color: var(--text-tertiary);
            text-align: center;
            margin-top: 0.75rem;
            font-style: italic;
        }
        
        .comparison-block {
            display: grid;
            grid-template-columns: 1fr auto 1fr;
            gap: 1rem;
            align-items: stretch;
            margin: 2rem 0;
        }
        .comparison-side {
            background: var(--bg-card);
            border-radius: var(--radius-md);
            padding: 1.5rem;
            border: 1px solid var(--border-color);
        }
        .comparison-side.left { border-top: 3px solid var(--accent-primary); }
        .comparison-side.right { border-top: 3px solid var(--accent-secondary); }
        .comparison-side h4 { margin-bottom: 0.75rem; }
        .comparison-side ul { padding-left: 1.25rem; }
        .comparison-side li { margin-bottom: 0.5rem; color: var(--text-secondary); font-size: 0.95rem; }
        .comparison-divider {
            display: flex;
            align-items: center;
            font-size: 1.5rem;
            color: var(--text-tertiary);
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }
        .stat-card {
            background: var(--bg-card);
            border-radius: var(--radius-md);
            padding: 1.25rem;
            text-align: center;
            border: 1px solid var(--border-color);
            transition: transform 0.15s var(--ease);
        }
        .stat-card:hover { transform: translateY(-3px); box-shadow: var(--shadow-lg); }
        .stat-value {
            font-size: 1.75rem;
            font-weight: 700;
            color: var(--accent-primary);
            display: block;
            font-family: var(--font-heading);
        }
        .stat-label {
            font-size: 0.8rem;
            color: var(--text-tertiary);
            margin-top: 0.25rem;
        }
        
        @media (max-width: 768px) {
            .comparison-block { grid-template-columns: 1fr; }
            .comparison-divider { justify-content: center; padding: 0.5rem 0; }
            .chart-grid { grid-template-columns: 1fr; }
        }
        
        /* ===========================================
           SIDEBAR TABS & PANELS
           =========================================== */
        .sidebar-tabs {
            display: flex;
            gap: 2px;
            margin-bottom: 1rem;
            background: var(--bg-primary);
            border-radius: var(--radius-sm);
            padding: 2px;
        }
        .sidebar-tab {
            flex: 1;
            padding: 0.5rem 0.25rem;
            background: transparent;
            border: none;
            color: var(--text-tertiary);
            font-family: var(--font-heading);
            font-size: 0.8rem;
            font-weight: 500;
            cursor: pointer;
            border-radius: 6px;
            transition: all 0.15s var(--ease);
        }
        .sidebar-tab:hover { color: var(--text-secondary); }
        .sidebar-tab.active {
            background: var(--bg-elevated);
            color: var(--accent-primary);
        }
        
        /* ===========================================
           NOTES SYSTEM
           =========================================== */
        .note-card {
            background: var(--bg-primary);
            border: 1px solid var(--border-color);
            border-radius: var(--radius-sm);
            padding: 0.625rem;
            font-size: 0.85rem;
            position: relative;
            cursor: pointer;
            transition: border-color 0.15s var(--ease), transform 0.15s var(--ease);
        }
        .note-card:hover { border-color: var(--border-hover); }
        .note-card.active {
            border-color: var(--accent-primary);
            transform: translateY(-1px);
        }
        .note-card.focused {
            border-left: 3px solid var(--accent-secondary);
            padding-left: calc(0.625rem - 2px);
        }
        .note-card .note-citation {
            font-size: 0.75rem;
            color: var(--text-tertiary);
            border-left: 2px solid var(--accent-primary);
            padding-left: 0.5rem;
            margin-bottom: 0.375rem;
            font-style: italic;
            line-height: 1.4;
        }
        .note-card .note-body {
            color: var(--text-secondary);
            line-height: 1.5;
        }
        .note-card .note-meta {
            font-size: 0.7rem;
            color: var(--text-tertiary);
            margin-top: 0.375rem;
            display: flex;
            justify-content: space-between;
        }
        .note-card .note-delete {
            background: none;
            border: none;
            color: var(--text-tertiary);
            cursor: pointer;
            font-size: 0.75rem;
            padding: 0;
        }
        .note-card .note-delete:hover { color: var(--accent-error); }
        .note-card .note-focus {
            background: none;
            border: none;
            color: var(--accent-secondary);
            cursor: pointer;
            font-size: 0.75rem;
            padding: 0;
            margin-right: 0.5rem;
        }
        .note-card .note-focus:hover { color: var(--accent-primary); }
        .note-reader {
            margin-top: 0.75rem;
            padding: 0.75rem;
            border: 1px solid var(--border-color);
            border-radius: var(--radius-sm);
            background: var(--bg-primary);
            overflow-y: auto;
            max-height: 34vh;
        }
        .note-reader .reader-title {
            font-size: 0.8rem;
            color: var(--text-tertiary);
            margin-bottom: 0.5rem;
        }
        .note-reader .reader-content {
            color: var(--text-secondary);
            line-height: 1.65;
            font-size: 0.9rem;
        }
        .note-reader .reader-content code {
            background: var(--bg-tertiary);
            padding: 0.1em 0.35em;
            border-radius: 4px;
            font-size: 0.85em;
        }
        .note-draft-preview {
            margin-top: 0.5rem;
            max-height: 20vh;
        }
        
        /* ===========================================
           TEXT HIGHLIGHT
           =========================================== */
        .text-highlight {
            background: rgba(246, 193, 119, 0.25);
            border-bottom: 2px solid var(--accent-primary);
            cursor: pointer;
            transition: background 0.15s;
        }
        .text-highlight:hover {
            background: rgba(246, 193, 119, 0.4);
        }
        
        /* Highlight context menu */
        .highlight-tooltip {
            position: fixed;
            background: var(--bg-elevated);
            border: 1px solid var(--border-color);
            border-radius: var(--radius-sm);
            box-shadow: var(--shadow-lg);
            padding: 0.25rem;
            display: none;
            z-index: 1001;
            gap: 2px;
        }
        .highlight-tooltip.show { display: flex; }
        .highlight-tooltip button {
            background: transparent;
            border: none;
            color: var(--text-secondary);
            padding: 0.375rem 0.625rem;
            cursor: pointer;
            font-size: 0.8rem;
            font-family: var(--font-heading);
            border-radius: 4px;
            white-space: nowrap;
        }
        .highlight-tooltip button:hover {
            background: var(--bg-tertiary);
            color: var(--accent-primary);
        }
    
    </style>
    <link rel="stylesheet" href="./app-shell.css?v=10" />
</head>
<body data-shell-page="lecture">
    <!-- Progress Tracker -->
    <div class="progress-tracker">
        <div class="progress-bar" id="progressBar"></div>
    </div>

    <div class="page-container">
        <!-- Left Sidebar -->
        <aside class="sidebar-left">
            <!-- Sidebar Tabs -->
            <div class="sidebar-tabs">
                <button class="sidebar-tab active" data-tab="toc" onclick="switchSidebarTab('toc')">Contents</button>
                <button class="sidebar-tab" data-tab="pdf" onclick="switchSidebarTab('pdf')">PDF</button>
                <button class="sidebar-tab" data-tab="notes" onclick="switchSidebarTab('notes')">Notes</button>
            </div>
            
            <!-- Tab: Table of Contents -->
            <div class="sidebar-panel" id="panel-toc">
                <ul style="list-style: none; padding: 0;">
                    <li style="margin-bottom: 0.75rem;">
                        <a href="#overview" class="toc-link">Overview</a>
                    </li>
                    
            <li style="margin-bottom: 0.75rem;">
                <a href="#concept-1" class="toc-link">Large Language Models (LLMs)</a>
            </li>
        
            <li style="margin-bottom: 0.75rem;">
                <a href="#concept-2" class="toc-link">Emergent Capabilities</a>
            </li>
        
            <li style="margin-bottom: 0.75rem;">
                <a href="#concept-3" class="toc-link">Transformer Architecture</a>
            </li>
        
            <li style="margin-bottom: 0.75rem;">
                <a href="#concept-4" class="toc-link">Computing and Infrastructure Requirements</a>
            </li>
        
            <li style="margin-bottom: 0.75rem;">
                <a href="#concept-5" class="toc-link">RLHF and Chain of Thought</a>
            </li>
        
            <li style="margin-bottom: 0.75rem;">
                <a href="#concept-6" class="toc-link">Vertical Domain Adaptation</a>
            </li>
        
                </ul>
                
                <div style="margin-top: 3rem; padding: 1rem; background: var(--bg-elevated); border-radius: 8px; font-size: 0.85rem;">
                    <div style="color: var(--text-tertiary); margin-bottom: 0.5rem;">Course Stats</div>
                    <div style="color: var(--text-secondary);">
                        <div>6 Concepts</div>
                        <div>40 Images</div>
                        <div>83 Tables</div>
                    </div>
                </div>
            </div>
            
            <!-- Tab: PDF Viewer -->
            <div class="sidebar-panel" id="panel-pdf" style="display:none;">
                <div id="pdfViewerContainer" style="height: calc(100vh - 80px); display: flex; flex-direction: column;">
                    <p style="font-size: 0.85rem; color: var(--text-tertiary); margin-bottom: 0.75rem;">Source: Lec 10 LLM_v1.3.pdf</p>
                    <iframe id="pdfFrame" src="../pdfs/Lec 10 LLM_v1.3.pdf" style="flex:1; width:100%; border:none; border-radius: var(--radius-sm); background: var(--bg-tertiary);"></iframe>
                </div>
            </div>
            
            <!-- Tab: Notes -->
            <div class="sidebar-panel" id="panel-notes" style="display:none;">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.75rem;">
                    <span style="font-size: 0.85rem; color: var(--text-tertiary);" id="notesCount">0 notes</span>
                    <button onclick="exportNotesToObsidian()" class="action-btn" style="width:auto; padding: 0.4rem 0.75rem; font-size: 0.8rem;">Export .md</button>
                </div>
                <div id="notesList" style="display: flex; flex-direction: column; gap: 0.5rem; max-height: 32vh; overflow-y: auto;"></div>
                <div id="noteReader" class="note-reader">
                    <div class="reader-title">Reading</div>
                    <div class="reader-content">Click a note in history to read it here.</div>
                </div>
                <div style="margin-top: 0.75rem; border-top: 1px solid var(--border-color); padding-top: 0.75rem;">
                    <textarea id="noteInput" oninput="handleNoteInputChange(this.value)" placeholder="Write a note (Markdown supported)..." style="width:100%; min-height: 80px; background: var(--bg-primary); border: 1px solid var(--border-color); border-radius: var(--radius-sm); padding: 0.5rem; color: var(--text-primary); font-family: var(--font-mono); font-size: 0.85rem; resize: vertical;"></textarea>
                    <div id="noteDraftPreview" class="note-reader note-draft-preview">
                        <div class="reader-title">Live Preview</div>
                        <div class="reader-content" id="noteDraftPreviewContent">Type in the note box to preview Markdown rendering in real time.</div>
                    </div>
                    <button onclick="addFreeNote()" class="action-btn" style="margin-top: 0.375rem;">Add Note</button>
                </div>
            </div>
        </aside>

        <div class="column-resizer" id="resizerLeft" role="separator" aria-orientation="vertical" aria-label="Resize left sidebar"></div>

        <!-- Main Content -->
        <main class="main-content">
            <header id="overview">
                <h1>Lec 10 LLM_v1.3</h1>
                <p style="font-size: 1.1rem; color: var(--text-tertiary); margin-bottom: 2rem;">
                    Interactive Learning Experience • Source: Lec 10 LLM_v1.3.pdf
                </p>
                
                <!-- Course Overview -->
                <div class="feynman-block" style="border-left-color: #9f7aea;">
                    <h4>Course Overview</h4>
                    <p><strong>Difficulty:</strong> Intermediate</p>
                    
                    <h5 style="margin-top: 1.5rem; margin-bottom: 0.5rem; color: var(--accent-primary);">Prerequisites:</h5>
                    <ul style="margin-left: 1.5rem;">
                        <li>Basic Machine Learning concepts</li><li>Fundamentals of Natural Language Processing (NLP)</li><li>Understanding of Deep Learning and Neural Networks</li><li>Basic knowledge of Data Science infrastructure</li>
                    </ul>
                    
                    <h5 style="margin-top: 1.5rem; margin-bottom: 0.5rem; color: var(--accent-secondary);">Learning Objectives:</h5>
                    <ul style="margin-left: 1.5rem;">
                        <li>Trace the historical development of LLMs from the Transformer architecture to modern models like GPT-4 and DeepSeek.</li><li>Identify the three pillars of LLM development: data resources, algorithmic models, and computing power.</li><li>Explain the relationship between model parameter size and the emergence of new cognitive capabilities.</li><li>Analyze the technical roadmap for applying LLMs to specialized vertical domains such as finance.</li>
                    </ul>
                </div>
            </header>

            <!-- Concept Sections -->
            
        <section id="concept-1" class="concept-section">
            <h2>Large Language Models (LLMs)</h2>
            
            <!-- Simple Analogy -->
            <div class="feynman-block" style="border-left-color: var(--accent-primary);">
                <h4>Simple Analogy</h4>
                <p>An LLM is like a super-powered version of your phone's autocomplete that has read every book in the world's largest library. It doesn't 'know' facts like a person does; instead, it has become a master at predicting which word most logically follows another based on patterns it saw in its massive reading list.</p>
            </div>
            
            <!-- Why It Matters -->
            <div class="feynman-block" style="border-left-color: var(--accent-secondary);">
                <h4>Why This Matters</h4>
                <p>LLMs allow machines to understand and generate human language, bridging the gap between complex computer code and natural communication. This allows for the automation of high-level cognitive tasks like summarizing legal documents, writing software, or analyzing massive financial datasets in seconds.</p>
            </div>
            
            <!-- Visualization -->
            
        <div class="diagram-container">
            <div class="diagram-title">LLM Development and Specialization Pipeline</div>
            <div class="mermaid">
flowchart TD
    A[Massive General Data] --> B[Pre-training]
    B --> C{Base LLM}
    C -->|Emergent Capabilities| D[General Tasks: Chat, Summarization]
    C --> E[Fine-tuning with Domain Data]
    E --> F[Vertical Model: Finance/Legal]
    F --> G[Applications: Risk Analysis, Trading Signals]
            </div>
            <div class="diagram-caption">The journey from raw data to specialized financial applications.</div>
        </div>
        
            
            <!-- Deep Explanation -->
            <div class="expandable">
                <div class="expandable-header">
                    <span>Deep Dive: Detailed Explanation</span>
                    <span class="expandable-icon">▼</span>
                </div>
                <div class="expandable-content">
                    <div class="expandable-content-inner">
                        <p>Large Language Models are neural networks with billions of parameters trained on vast amounts of text data to predict the next token in a sequence. As these models grow in size, they develop 'emergent capabilities,' such as the ability to reason or follow complex instructions, which were not explicitly programmed into them. While a general LLM like GPT-4 is a 'jack of all trades,' it can be specialized through a process called fine-tuning. This involves further training the model on a smaller, high-quality dataset—such as financial records or medical journals—to create a 'vertical domain model' that understands industry-specific jargon and logic with much higher precision than the base model.</p>
                        <div style="margin-top: 1rem; padding: 1rem; background: var(--bg-elevated); border-radius: 8px; font-size: 0.95rem; color: var(--text-tertiary);"><strong>From lecture:</strong><br>Road Map

•  A comprehensive review of the development history and current status of
Large Language Models (LLMs).

•  The emergence of capabilities and shortcomings of Large Language
Models.

•  Introduction to the application and technical roadmap of Large Language
Models: Vertical domain large models and model fine-tuning.

•  Applications of Large Language Models in the financial sector.
1</div>
                    </div>
                </div>
            </div>
            
            <!-- Practical Example -->
            <div class="expandable open">
                <div class="expandable-header">
                    <span>Practical Example</span>
                    <span class="expandable-icon">▼</span>
                </div>
                <div class="expandable-content">
                    <div class="expandable-content-inner">
                        <p>Suppose a bank wants to automate credit risk assessments. They take a general LLM and fine-tune it on thousands of past loan applications and market reports; this 'Vertical Model' can then read a new 50-page filing and instantly flag that a 15% increase in debt-to-equity ratio is a high-risk signal, whereas a general model might only see it as a neutral numerical change.</p>
                    </div>
                </div>
            </div>
            
            <!-- Common Mistakes -->
            <div class="feynman-block" style="border-left-color: var(--accent-warning);">
                <h4>Common Mistakes</h4>
                <p>Students often think LLMs are 'searching' a database or the internet to find answers like Google does. In reality, they are generating each word one-by-one based on statistical probability, which is why they can 'hallucinate' or confidently state facts that do not exist.</p>
            </div>
            
            <!-- Quiz Questions -->
            
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 1:</strong> In the context of the LLM technical roadmap, what is the primary purpose of developing 'vertical domain large models'?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        To increase the general conversational ability of the model for everyday use.
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        To specialize a model for specific industries or specialized knowledge bases.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        To reduce the total number of parameters to make models run on mobile devices.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        To eliminate the need for any data during the training process.
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! Vertical domain models are specifically designed to provide high-level expertise and accuracy within a particular industry or field.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. Vertical domain models are specifically designed to provide high-level expertise and accuracy within a particular industry or field.
                    </div>
                </div>
                
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 2:</strong> Which of the following best describes 'emergent capabilities' in Large Language Models?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        Features that are manually coded by engineers before the training begins.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        The hardware's ability to cool down more efficiently during high workloads.
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        Abilities that appear in large-scale models that were not present in smaller versions.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        The process of deleting outdated information from the model's memory.
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! Emergent capabilities refer to complex skills that manifest only after a model reaches a certain threshold of size and computational power.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. Emergent capabilities refer to complex skills that manifest only after a model reaches a certain threshold of size and computational power.
                    </div>
                </div>
                
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 3:</strong> Based on the roadmap provided, how are Large Language Models typically utilized within the financial sector?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        For physical security monitoring of bank vaults and hardware.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        To generate cryptocurrency through decentralized mining algorithms.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        To replace the need for central banking regulations and laws.
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        For tasks such as analyzing financial reports and performing sentiment analysis.
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! LLMs in finance are primarily used to process vast amounts of textual data to assist in risk assessment and market analysis.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. LLMs in finance are primarily used to process vast amounts of textual data to assist in risk assessment and market analysis.
                    </div>
                </div>
                
        </section>
        
        <section id="concept-2" class="concept-section">
            <h2>Emergent Capabilities</h2>
            
            <!-- Simple Analogy -->
            <div class="feynman-block" style="border-left-color: var(--accent-primary);">
                <h4>Simple Analogy</h4>
                <p>Emergent capabilities are like heating water: as you add heat, the temperature rises gradually, but at exactly 100°C, the water suddenly undergoes a 'phase transition' and turns into steam. The ability to power a steam engine isn't present at 99°C; it only emerges once a specific threshold of energy is crossed.</p>
            </div>
            
            <!-- Why It Matters -->
            <div class="feynman-block" style="border-left-color: var(--accent-secondary);">
                <h4>Why This Matters</h4>
                <p>These capabilities allow AI to perform complex tasks like legal reasoning or creative writing that they weren't explicitly programmed to do. Understanding these thresholds helps researchers predict when a model will become powerful enough to handle high-stakes applications in medicine, finance, or engineering.</p>
            </div>
            
            <!-- Visualization -->
            
        <div class="chart-container">
            <div class="chart-title">The Scaling Threshold: Emergence of Logic</div>
            <canvas id="chart-2" style="max-height:380px;"></canvas>
            <div class="chart-caption">Performance on complex tasks remains near zero until a critical scale (parameters) is reached, leading to a sudden 'jump' in capability.</div>
        </div>
        <script>
        document.addEventListener('DOMContentLoaded', function() {
            const ctx = document.getElementById('chart-2');
            if (ctx && typeof Chart !== 'undefined') {
                new Chart(ctx, {
                    type: 'line',
                    data: {
                        labels: ["100M", "1B", "10B", "70B", "175B", "500B"],
                        datasets: [{"label": "Logical Reasoning Accuracy (%)", "data": [0.5, 1, 2, 15, 65, 82], "borderColor": "#4299e1", "backgroundColor": "rgba(66,153,225,0.15)", "tension": 0.4, "fill": true}]
                    },
                    options: {
                        plugins: {
                            legend: { position: 'bottom' },
                            tooltip: { mode: 'index', intersect: false }
                        },
                        scales: {
                y: { beginAtZero: true, grid: { color: 'rgba(255,255,255,0.05)' } },
                x: { grid: { color: 'rgba(255,255,255,0.05)' } }
            }
                    }
                });
            }
        });
        </script>
        
            
            <!-- Deep Explanation -->
            <div class="expandable">
                <div class="expandable-header">
                    <span>Deep Dive: Detailed Explanation</span>
                    <span class="expandable-icon">▼</span>
                </div>
                <div class="expandable-content">
                    <div class="expandable-content-inner">
                        <p>Emergent capabilities are skills that appear in Large Language Models (LLMs) only after they reach a critical scale of parameters, training data, and computing power. While smaller models might show linear improvement on simple tasks, complex abilities—such as multi-step logical reasoning or understanding sarcasm—often show a 'jump' from near-zero accuracy to high proficiency once a certain size threshold is hit. These are not features coded by hand; instead, the model's increased capacity allows it to internalize deeper, more abstract patterns from the data that were previously invisible to smaller architectures.</p>
                        <div style="margin-top: 1rem; padding: 1rem; background: var(--bg-elevated); border-radius: 8px; font-size: 0.95rem; color: var(--text-tertiary);"><strong>From lecture:</strong><br>data resources, algorithm and model elements, and funding and computing resources. Based on the current market characteristics, data resources and funding/computing resources are the foundational elements for large model development, while algorithms are the core element.

•  Algorithms and models are the core elements that differentiate the
development capabilities of large language models. The richness of the model, accuracy, and emergent capabilities are all key indicators for evaluating the </div>
                    </div>
                </div>
            </div>
            
            <!-- Practical Example -->
            <div class="expandable open">
                <div class="expandable-header">
                    <span>Practical Example</span>
                    <span class="expandable-icon">▼</span>
                </div>
                <div class="expandable-content">
                    <div class="expandable-content-inner">
                        <p>A model with 1 billion parameters may consistently fail the GSM8k math benchmark, scoring near 0% because it cannot handle multi-step logic. However, when scaled to 100 billion parameters using the same training algorithms, the model may suddenly achieve 60% accuracy. This 'Chain of Thought' reasoning emerges purely from the scale of the neural network and the volume of data processed, not from a change in the underlying code.</p>
                    </div>
                </div>
            </div>
            
            <!-- Common Mistakes -->
            <div class="feynman-block" style="border-left-color: var(--accent-warning);">
                <h4>Common Mistakes</h4>
                <p>Many students assume emergent capabilities are 'hidden features' or specific updates manually added by developers during a version release. In reality, these abilities are unintended and often surprise the developers themselves, appearing spontaneously as a byproduct of scaling up the system.</p>
            </div>
            
            <!-- Quiz Questions -->
            
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 1:</strong> According to the provided text, which element is considered the core factor that differentiates the development capabilities and quality of large language models?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        Data resources
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        Funding resources
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        Algorithms and models
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        Computing resources
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! The text states that algorithms and models are the core elements that differentiate development capabilities and determine indicators like richness and emergent capabilities.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. The text states that algorithms and models are the core elements that differentiate development capabilities and determine indicators like richness and emergent capabilities.
                    </div>
                </div>
                
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 2:</strong> The total amount of data resources utilized in large model development primarily determines which of the following?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        The specific GPU model required for training
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        The size of model parameters and the total number of training iterations
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        The salary of the AI development team
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        The reinforcement learning feedback loop
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! The content specifies that the total amount of data determines both the size of the model parameters and the total number of training iterations.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. The content specifies that the total amount of data determines both the size of the model parameters and the total number of training iterations.
                    </div>
                </div>
                
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 3:</strong> How does the computational power of NVIDIA’s H100 compare to the A100 80GB card according to the provided information?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        It provides double the computational power of an A100 card.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        It is slightly slower but consumes significantly less power.
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        It provides 3-5 times the power, and can reach up to 10 times in some tasks.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        It is only used for processing customized private databases.
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! The text notes that the H100 provides 3-5 times the LLM computational power of an A100, reaching up to 10 times in specific tasks.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. The text notes that the H100 provides 3-5 times the LLM computational power of an A100, reaching up to 10 times in specific tasks.
                    </div>
                </div>
                
        </section>
        
        <section id="concept-3" class="concept-section">
            <h2>Transformer Architecture</h2>
            
            <!-- Simple Analogy -->
            <div class="feynman-block" style="border-left-color: var(--accent-primary);">
                <h4>Simple Analogy</h4>
                <p>Imagine a classroom where every student is reading the same page at once. Instead of one student reading a sentence aloud word-by-word, every student points to a different word and shouts out which other words on the page are most related to it, instantly revealing the context of the whole story.</p>
            </div>
            
            <!-- Why It Matters -->
            <div class="feynman-block" style="border-left-color: var(--accent-secondary);">
                <h4>Why This Matters</h4>
                <p>This architecture is the 'engine' inside models like GPT-4 and BERT, allowing AI to process massive amounts of data simultaneously rather than one piece at a time. It enables computers to understand long-range context, such as remembering a character's name mentioned at the start of a book when reading the final chapter.</p>
            </div>
            
            <!-- Visualization -->
            
        <div class="comparison-block">
            <div class="comparison-side left">
                <h4>🔵 Old Way (RNN/LSTM)</h4>
                <ul><li>Processes words one-by-one</li><li>Slow: Step B must wait for Step A</li><li>Forgets early words in long sentences</li><li>Sequential processing</li></ul>
            </div>
            <div class="comparison-divider">vs</div>
            <div class="comparison-side right">
                <h4>🟢 Transformer Way</h4>
                <ul><li>Processes all words simultaneously</li><li>Fast: Parallel processing on GPUs</li><li>Connects words regardless of distance</li><li>Self-Attention mechanism</li></ul>
            </div>
        </div>
        
            
            <!-- Deep Explanation -->
            <div class="expandable">
                <div class="expandable-header">
                    <span>Deep Dive: Detailed Explanation</span>
                    <span class="expandable-icon">▼</span>
                </div>
                <div class="expandable-content">
                    <div class="expandable-content-inner">
                        <p>The Transformer replaces the old method of processing data in a sequence (RNNs) with a mechanism called 'Self-Attention.' This allows the model to look at every word in a sentence at the same time and mathematically calculate how much 'attention' or weight one word should give to others to understand context. For example, in the phrase 'the bank of the river,' the word 'bank' would pay high attention to 'river' to distinguish it from a financial institution. Because it processes everything in parallel rather than one-by-one, it is significantly faster to train and can handle much larger datasets than previous neural network designs.</p>
                        <div style="margin-top: 1rem; padding: 1rem; background: var(--bg-elevated); border-radius: 8px; font-size: 0.95rem; color: var(--text-tertiary);"><strong>From lecture:</strong><br>The foundational neural network design introduced in 2017 that enables parallel processing of data and serves as the backbone for models like GPT and BERT.</div>
                    </div>
                </div>
            </div>
            
            <!-- Practical Example -->
            <div class="expandable open">
                <div class="expandable-header">
                    <span>Practical Example</span>
                    <span class="expandable-icon">▼</span>
                </div>
                <div class="expandable-content">
                    <div class="expandable-content-inner">
                        <p>Consider the sentence 'The animal didn't cross the street because it was too tired.' The Transformer calculates an attention score for the word 'it'; it might assign a weight of 0.9 to 'animal' and 0.05 to 'street.' These numerical weights tell the model that 'it' refers to the animal, allowing the model to maintain logical consistency when translating or generating text.</p>
                    </div>
                </div>
            </div>
            
            <!-- Common Mistakes -->
            <div class="feynman-block" style="border-left-color: var(--accent-warning);">
                <h4>Common Mistakes</h4>
                <p>Students often assume Transformers read text from left to right like humans do. In reality, they process the entire block of text at once, which is why they require 'positional encodings' to manually tell the model which word comes first, second, or third.</p>
            </div>
            
            <!-- Quiz Questions -->
            
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 1:</strong> What is a primary advantage of the Transformer architecture compared to traditional Recurrent Neural Networks (RNNs)?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        It processes data sequentially one word at a time
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        It enables parallel processing of data sequences
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        It relies exclusively on convolutional layers for context
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        It requires significantly less data to achieve high accuracy
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! Unlike RNNs that process tokens one by one, Transformers can process entire sequences simultaneously, leading to much faster training through parallelization.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. Unlike RNNs that process tokens one by one, Transformers can process entire sequences simultaneously, leading to much faster training through parallelization.
                    </div>
                </div>
                
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 2:</strong> Which 2017 research paper introduced the Transformer architecture to the field of Natural Language Processing?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        ImageNet Classification with Deep CNNs
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        Attention Is All You Need
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        Deep Residual Learning for Image Recognition
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        BERT: Pre-training of Deep Bidirectional Transformers
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! The paper 'Attention Is All You Need' established the Transformer design by replacing recurrence with self-attention mechanisms.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. The paper 'Attention Is All You Need' established the Transformer design by replacing recurrence with self-attention mechanisms.
                    </div>
                </div>
                
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 3:</strong> Which specific mechanism allows a Transformer to weigh the importance of different words in a sequence relative to a target word?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        Backpropagation through time
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        Gradient Descent
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        Self-Attention
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        Max Pooling
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! Self-attention enables the model to look at other words in the input sequence to better understand the context of a specific word.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. Self-attention enables the model to look at other words in the input sequence to better understand the context of a specific word.
                    </div>
                </div>
                
        </section>
        
        <section id="concept-4" class="concept-section">
            <h2>Computing and Infrastructure Requirements</h2>
            
            <!-- Simple Analogy -->
            <div class="feynman-block" style="border-left-color: var(--accent-primary);">
                <h4>Simple Analogy</h4>
                <p>Training a state-of-the-art LLM is like trying to cook a banquet for a million people simultaneously; you cannot use a household kitchen, you need a massive industrial factory with thousands of specialized burners and its own dedicated power plant.</p>
            </div>
            
            <!-- Why It Matters -->
            <div class="feynman-block" style="border-left-color: var(--accent-secondary);">
                <h4>Why This Matters</h4>
                <p>High-end hardware acts as the primary bottleneck for AI progress, creating a 'compute moat' where only the most well-funded organizations can develop foundation models. This infrastructure determines whether a model takes weeks or decades to learn from its training data.</p>
            </div>
            
            <!-- Visualization -->
            
        <div class="chart-container">
            <div class="chart-title">Estimated Training Costs of Major LLMs (USD)</div>
            <canvas id="chart-4" style="max-height:380px;"></canvas>
            <div class="chart-caption">The exponential rise in infrastructure requirements and funding needed for training foundation models.</div>
        </div>
        <script>
        document.addEventListener('DOMContentLoaded', function() {
            const ctx = document.getElementById('chart-4');
            if (ctx && typeof Chart !== 'undefined') {
                new Chart(ctx, {
                    type: 'bar',
                    data: {
                        labels: ["GPT-3 (2020)", "PaLM (2022)", "GPT-4 (2023)", "Llama 3 400B+ (2024 Est.)"],
                        datasets: [{"label": "Estimated Cost (Millions USD)", "data": [4.6, 12, 100, 250], "borderColor": "#4299e1", "backgroundColor": "rgba(66,153,225,0.15)"}]
                    },
                    options: {
                        plugins: {
                            legend: { position: 'bottom' },
                            tooltip: { mode: 'index', intersect: false }
                        },
                        scales: {
                y: { beginAtZero: true, grid: { color: 'rgba(255,255,255,0.05)' } },
                x: { grid: { color: 'rgba(255,255,255,0.05)' } }
            }
                    }
                });
            }
        });
        </script>
        
            
            <!-- Deep Explanation -->
            <div class="expandable">
                <div class="expandable-header">
                    <span>Deep Dive: Detailed Explanation</span>
                    <span class="expandable-icon">▼</span>
                </div>
                <div class="expandable-content">
                    <div class="expandable-content-inner">
                        <p>Large Language Models consist of billions of parameters that require trillions of mathematical operations to optimize. Unlike standard computer processors (CPUs) that handle tasks sequentially, LLMs rely on Graphics Processing Units (GPUs) designed for massive parallel processing. High-end units like the NVIDIA H100 are specialized to handle the specific matrix math required for deep learning and use high-speed interconnects to function as a single, giant supercomputer. This infrastructure requires not only the chips themselves but also specialized data centers with immense cooling capacity and electrical footprints equivalent to small cities.</p>
                        <div style="margin-top: 1rem; padding: 1rem; background: var(--bg-elevated); border-radius: 8px; font-size: 0.95rem; color: var(--text-tertiary);"><strong>From lecture:</strong><br>The massive hardware resources (specifically high-end GPUs like NVIDIA A100/H100) and funding required to train and iterate on large-scale models.</div>
                    </div>
                </div>
            </div>
            
            <!-- Practical Example -->
            <div class="expandable open">
                <div class="expandable-header">
                    <span>Practical Example</span>
                    <span class="expandable-icon">▼</span>
                </div>
                <div class="expandable-content">
                    <div class="expandable-content-inner">
                        <p>Meta recently deployed a cluster containing 350,000 NVIDIA H100 GPUs to train their next generation of models. With each chip costing approximately $30,000, the hardware investment alone exceeds $10 billion. This massive scale is necessary because modern models like Llama 3 are trained on trillions of tokens, requiring months of continuous uptime across the entire cluster.</p>
                    </div>
                </div>
            </div>
            
            <!-- Common Mistakes -->
            <div class="feynman-block" style="border-left-color: var(--accent-warning);">
                <h4>Common Mistakes</h4>
                <p>Students often assume that having a powerful gaming PC is sufficient for LLM training, overlooking that enterprise models require thousands of GPUs working in sync because the model size far exceeds the memory capacity of any single consumer device.</p>
            </div>
            
            <!-- Quiz Questions -->
            
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 1:</strong> Which specific hardware components are currently considered the industry standard for providing the massive parallel processing power needed to train large-scale AI models?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        Consumer-grade CPUs with high clock speeds
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        Standard solid-state drives (SSDs) for fast data retrieval
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        NVIDIA A100 and H100 GPUs
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        General-purpose integrated circuits (ASICs) used in basic calculators
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! High-end GPUs like the A100 and H100 are specifically engineered to handle the intensive matrix calculations required for training large-scale neural networks.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. High-end GPUs like the A100 and H100 are specifically engineered to handle the intensive matrix calculations required for training large-scale neural networks.
                    </div>
                </div>
                
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 2:</strong> What is one of the primary economic challenges associated with the infrastructure requirements of modern foundational models?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        The decreasing cost of data center cooling systems
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        The massive capital investment required to acquire thousands of specialized GPUs
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        A lack of available software to run on high-end hardware
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        The minimal electricity consumption of large-scale computing clusters
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! The extreme cost of high-end hardware and the energy required to power it creates a high barrier to entry that only well-funded organizations can typically afford.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. The extreme cost of high-end hardware and the energy required to power it creates a high barrier to entry that only well-funded organizations can typically afford.
                    </div>
                </div>
                
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 3:</strong> Why is high-end computing infrastructure critical for the 'iteration' phase of model development?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="true">
                        It allows researchers to test and refine models much faster by reducing training time from months to days.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        It eliminates the need for human data scientists to monitor the training process.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        It ensures that the model can run on low-power mobile devices immediately.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        It reduces the amount of training data required to achieve high accuracy.
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! Massive infrastructure enables rapid iteration by shortening the time it takes to train a model, allowing developers to experiment and fix errors more efficiently.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. Massive infrastructure enables rapid iteration by shortening the time it takes to train a model, allowing developers to experiment and fix errors more efficiently.
                    </div>
                </div>
                
        </section>
        
        <section id="concept-5" class="concept-section">
            <h2>RLHF and Chain of Thought</h2>
            
            <!-- Simple Analogy -->
            <div class="feynman-block" style="border-left-color: var(--accent-primary);">
                <h4>Simple Analogy</h4>
                <p>RLHF is like a coach giving a gymnast feedback on their form to ensure they look graceful and follow the rules, while Chain of Thought is like the gymnast talking themselves through each step of a complex routine to ensure they don't miss a move.</p>
            </div>
            
            <!-- Why It Matters -->
            <div class="feynman-block" style="border-left-color: var(--accent-secondary);">
                <h4>Why This Matters</h4>
                <p>These techniques transform a raw text-predictor into a reliable assistant that can perform complex financial analysis and follow safety guidelines. Without them, models are prone to 'hallucinating' incorrect logic or providing outputs that are biased, harmful, or socially inappropriate.</p>
            </div>
            
            <!-- Visualization -->
            
        <div class="comparison-block">
            <div class="comparison-side left">
                <h4>🔵 RLHF (Alignment)</h4>
                <ul><li>Optimized via human ranking and reward models</li><li>Focuses on safety, tone, and helpfulness</li><li>Permanent change to the model's weights</li><li>Prevents toxic or biased outputs</li></ul>
            </div>
            <div class="comparison-divider">vs</div>
            <div class="comparison-side right">
                <h4>🟢 Chain of Thought (Reasoning)</h4>
                <ul><li>Triggered by specific 'step-by-step' prompts</li><li>Focuses on logical flow and math accuracy</li><li>Dynamic process used during the response</li><li>Reduces errors in multi-step problems</li></ul>
            </div>
        </div>
        
            
            <!-- Deep Explanation -->
            <div class="expandable">
                <div class="expandable-header">
                    <span>Deep Dive: Detailed Explanation</span>
                    <span class="expandable-icon">▼</span>
                </div>
                <div class="expandable-content">
                    <div class="expandable-content-inner">
                        <p>Reinforcement Learning from Human Feedback (RLHF) is an alignment process where humans rank model responses, creating a 'reward model' that teaches the AI which outputs are most helpful and safe. In parallel, Chain of Thought (CoT) is a prompting technique that encourages the model to generate intermediate reasoning steps before reaching a conclusion. RLHF optimizes the model's general behavior and adherence to human intent via training, while CoT optimizes the model's logic and computational accuracy by breaking complex problems into smaller, sequential tasks during the inference stage.</p>
                        <div style="margin-top: 1rem; padding: 1rem; background: var(--bg-elevated); border-radius: 8px; font-size: 0.95rem; color: var(--text-tertiary);"><strong>From lecture:</strong><br>Algorithmic techniques including Reinforcement Learning from Human Feedback and reasoning prompts that improve model accuracy and alignment with human intent.</div>
                    </div>
                </div>
            </div>
            
            <!-- Practical Example -->
            <div class="expandable open">
                <div class="expandable-header">
                    <span>Practical Example</span>
                    <span class="expandable-icon">▼</span>
                </div>
                <div class="expandable-content">
                    <div class="expandable-content-inner">
                        <p>When calculating a company's debt-to-equity ratio, CoT forces the model to first list total liabilities, then list total equity, and finally perform the division ($10M / $5M = 2). RLHF ensures that the resulting explanation is delivered in a professional tone and includes a disclaimer that the AI is not a licensed financial advisor. This combination prevents the model from both skipping the math and giving irresponsible investment tips.</p>
                    </div>
                </div>
            </div>
            
            <!-- Common Mistakes -->
            <div class="feynman-block" style="border-left-color: var(--accent-warning);">
                <h4>Common Mistakes</h4>
                <p>Students often assume RLHF is used to teach the model new facts; in reality, it is used to refine how the model prioritizes and presents the knowledge it already gained during pre-training.</p>
            </div>
            
            <!-- Quiz Questions -->
            
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 1:</strong> What is the primary objective of using Reinforcement Learning from Human Feedback (RLHF) in model development?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        To reduce the physical hardware requirements for running large models
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        To align model outputs with human preferences, safety guidelines, and intent
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        To increase the raw speed at which the model generates text tokens
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        To expand the model's vocabulary by scraping more diverse web data
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! RLHF uses human rankings to fine-tune models, ensuring the generated responses are helpful, safe, and closely follow the user's intended goals.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. RLHF uses human rankings to fine-tune models, ensuring the generated responses are helpful, safe, and closely follow the user's intended goals.
                    </div>
                </div>
                
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 2:</strong> How does 'Chain of Thought' (CoT) prompting specifically improve model performance on complex tasks?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        By compressing the model's internal weights to save memory
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        By forcing the model to provide only the final answer without any context
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        By encouraging the model to generate intermediate reasoning steps before reaching a conclusion
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        By automatically translating the prompt into multiple languages to find the best answer
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! Chain of Thought prompting enables models to break down multi-step problems into logical sequences, which significantly enhances accuracy in reasoning and mathematics.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. Chain of Thought prompting enables models to break down multi-step problems into logical sequences, which significantly enhances accuracy in reasoning and mathematics.
                    </div>
                </div>
                
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 3:</strong> In the context of AI alignment, what is a shared benefit of combining reasoning prompts and RLHF?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="true">
                        It makes the model's decision-making process more transparent and its outcomes more reliable
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        It eliminates the need for any pre-training on large datasets
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        It reduces the context window size required for the model to function
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        It ensures that the model can only be used for basic retrieval tasks
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! These techniques work together to ensure that the model's logical path is visible through reasoning and its final output is calibrated to human standards of correctness.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. These techniques work together to ensure that the model's logical path is visible through reasoning and its final output is calibrated to human standards of correctness.
                    </div>
                </div>
                
        </section>
        
        <section id="concept-6" class="concept-section">
            <h2>Vertical Domain Adaptation</h2>
            
            <!-- Simple Analogy -->
            <div class="feynman-block" style="border-left-color: var(--accent-primary);">
                <h4>Simple Analogy</h4>
                <p>Think of a general practitioner doctor who returns to school for several years to specialize in neurosurgery. While they already understand the human body generally, they require intensive, focused training on specific instruments and procedures to perform complex brain surgeries safely.</p>
            </div>
            
            <!-- Why It Matters -->
            <div class="feynman-block" style="border-left-color: var(--accent-secondary);">
                <h4>Why This Matters</h4>
                <p>General-purpose models often fail at professional tasks because they treat specialized terms with their common dictionary definitions. Vertical adaptation is crucial for high-stakes industries like finance or law, where a single misunderstood technical term can lead to massive financial loss or legal non-compliance.</p>
            </div>
            
            <!-- Visualization -->
            
        <div class="comparison-block">
            <div class="comparison-side left">
                <h4>🔵 General-Purpose LLM</h4>
                <ul><li>Trained on Wikipedia, news, and social media</li><li>Broad but shallow knowledge</li><li>High hallucination rate in niche fields</li><li>Confused by industry-specific jargon</li></ul>
            </div>
            <div class="comparison-divider">vs</div>
            <div class="comparison-side right">
                <h4>🟢 Vertically Adapted LLM</h4>
                <ul><li>Fine-tuned on industry-specific documents</li><li>Deep expertise in a narrow 'vertical'</li><li>High accuracy for professional workflows</li><li>Mastery of technical terminology and logic</li></ul>
            </div>
        </div>
        
            
            <!-- Deep Explanation -->
            <div class="expandable">
                <div class="expandable-header">
                    <span>Deep Dive: Detailed Explanation</span>
                    <span class="expandable-icon">▼</span>
                </div>
                <div class="expandable-content">
                    <div class="expandable-content-inner">
                        <p>Vertical Domain Adaptation is a refinement process that transforms a broad 'foundation' model into a specialized expert by retraining it on industry-specific datasets. A base LLM is initially trained on a massive, diverse corpus (like the entire internet) to learn grammar and general logic. However, specialized sectors have unique vocabularies, reasoning patterns, and formatting standards. By performing 'fine-tuning'—which involves feeding the model curated professional data like financial audits, medical research, or legal statutes—the model adjusts its internal parameters to prioritize the linguistic patterns and logic of that specific 'vertical' industry, resulting in higher precision and fewer errors.</p>
                        <div style="margin-top: 1rem; padding: 1rem; background: var(--bg-elevated); border-radius: 8px; font-size: 0.95rem; color: var(--text-tertiary);"><strong>From lecture:</strong><br>The process of fine-tuning general-purpose LLMs for specific industries, such as the financial sector, to improve performance in specialized tasks.</div>
                    </div>
                </div>
            </div>
            
            <!-- Practical Example -->
            <div class="expandable open">
                <div class="expandable-header">
                    <span>Practical Example</span>
                    <span class="expandable-icon">▼</span>
                </div>
                <div class="expandable-content">
                    <div class="expandable-content-inner">
                        <p>A general LLM might interpret the word 'yield' as 'to give way' in a traffic context. In a financial vertical model adapted using thousands of SEC filings and bond prospectuses, the model automatically recognizes 'yield' as the annual interest rate on an investment. This specialization allows a bank's AI to accurately extract complex data from 500-page earnings reports with 98% accuracy compared to the 70% accuracy of a general-purpose model.</p>
                    </div>
                </div>
            </div>
            
            <!-- Common Mistakes -->
            <div class="feynman-block" style="border-left-color: var(--accent-warning);">
                <h4>Common Mistakes</h4>
                <p>Students often assume vertical adaptation is just adding a glossary or 'giving' the model more information to read. In reality, it is a structural change to the model's neural weights that alters how it perceives the relationship between words in a specific professional context.</p>
            </div>
            
            <!-- Quiz Questions -->
            
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 1:</strong> Which of the following best defines Vertical Domain Adaptation in the context of Large Language Models?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        The process of expanding a model's capabilities to speak multiple languages fluently.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        Increasing the physical server capacity to allow more users to access a general model.
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        Fine-tuning a general-purpose LLM on industry-specific data to improve its performance in a specialized field.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        Training a model from scratch using only raw, unorganized data from the public internet.
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! Vertical Domain Adaptation specifically refers to tailoring a broad, pre-trained model to the unique nuances and terminology of a particular industry or 'vertical'.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. Vertical Domain Adaptation specifically refers to tailoring a broad, pre-trained model to the unique nuances and terminology of a particular industry or 'vertical'.
                    </div>
                </div>
                
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 2:</strong> Why would a company in the legal or medical sector choose Vertical Domain Adaptation over a standard general-purpose LLM?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        General-purpose models are unable to follow basic grammatical rules.
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        To ensure the model accurately understands specialized jargon and context-specific regulations.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        Vertical adaptation is the only method available to reduce the model's energy consumption.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        To prevent the model from being able to access any information outside of that specific industry.
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! Industry-specific adaptation helps models handle complex technical language and professional requirements that general-purpose models may misinterpret.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. Industry-specific adaptation helps models handle complex technical language and professional requirements that general-purpose models may misinterpret.
                    </div>
                </div>
                
                <div class="quiz-container">
                    <div class="quiz-question">
                        <strong>Question 3:</strong> What is typically the first step in the workflow of Vertical Domain Adaptation?
                    </div>
                    <div class="quiz-options">
                        
                    <div class="quiz-option" data-correct="false">
                        Designing a brand-new neural network architecture specifically for the industry.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        Deleting all previous knowledge from a general-purpose model to save space.
                    </div>
                    
                    <div class="quiz-option" data-correct="false">
                        Manually labeling millions of images to teach the model visual recognition.
                    </div>
                    
                    <div class="quiz-option" data-correct="true">
                        Selecting a pre-trained, general-purpose LLM to serve as the foundation for fine-tuning.
                    </div>
                    
                    </div>
                    <div class="quiz-feedback correct">
                        ✓ Correct! Vertical adaptation builds upon the broad knowledge base of an existing general-purpose model, refining it further with specialized datasets.
                    </div>
                    <div class="quiz-feedback incorrect">
                        ✗ Not quite. Vertical adaptation builds upon the broad knowledge base of an existing general-purpose model, refining it further with specialized datasets.
                    </div>
                </div>
                
        </section>
        
            
            <!-- Completion -->
            <div style="margin-top: 4rem; padding: 2rem; background: linear-gradient(135deg, var(--accent-primary), var(--accent-secondary)); border-radius: 12px; text-align: center; color: white;">
                <h3 style="margin-bottom: 1rem;">Course Complete!</h3>
                <p>You've reviewed all 6 main concepts. Keep practicing with the quizzes above.</p>
            </div>
        </main>

        <div class="column-resizer" id="resizerRight" role="separator" aria-orientation="vertical" aria-label="Resize right sidebar"></div>

        <!-- Right Sidebar: AI Assistant & Tools -->
        <aside class="sidebar-right">
            <div class="ai-chat">
                <div class="ai-chat-header">
                    <div>
                        <h3 style="margin: 0;">AI Study Assistant</h3>
                        <p style="font-size: 0.8rem; color: var(--text-tertiary); margin: 0;">Powered by Gemini</p>
                    </div>
                </div>
                
                <div class="ai-chat-messages" id="aiMessages">
                    <div class="ai-message assistant">
                        Hi! I'm your AI study assistant. Ask me anything about this topic, or request:
                        <ul style="margin-top: 0.5rem; padding-left: 1.5rem; font-size: 0.9rem;">
                            <li>Explanations in simpler terms</li>
                            <li>More examples</li>
                            <li>Practice questions</li>
                            <li>Connections to other concepts</li>
                        </ul>
                    </div>
                </div>
                
                <div class="ai-input-group">
                    <input 
                        type="text" 
                        class="ai-input" 
                        id="aiInput" 
                        placeholder="Ask a question..."
                        onkeypress="if(event.key==='Enter') sendAIMessage()"
                    />
                    <button class="ai-send-btn" onclick="sendAIMessage()">Send</button>
                </div>
            </div>

            <!-- Quick Actions -->
            <div style="margin-top: 2rem;">
                <h4 style="margin-bottom: 1rem; color: var(--text-tertiary);">Quick Actions</h4>
                <button onclick="reviewAllQuizzes()" class="action-btn">
                    Review All Quizzes
                </button>
                <button onclick="createSummary()" class="action-btn">
                    Generate Summary
                </button>
                <button onclick="window.print()" class="action-btn">
                    Print Notes
                </button>
            </div>
            
            <!-- Keyboard Shortcuts -->
            <div style="margin-top: 2rem; padding: 1rem; background: var(--bg-elevated); border-radius: 8px; font-size: 0.85rem;">
                <h5 style="margin-bottom: 0.75rem; color: var(--text-tertiary);">Shortcuts</h5>
                <div id="shortcutsDisplay" style="color: var(--text-secondary); line-height: 1.8;">
                    <div><kbd id="shortcutFocusAI">Alt+A</kbd> Focus AI</div>
                    <div><kbd id="shortcutSummary">Alt+S</kbd> Summary</div>
                </div>
            </div>
        </aside>
    </div>

    <script>
        
        // ── Gemini Proxy Configuration ──
        const GEMINI_PROXY_URL = '../api/gemini';
        const LAYOUT_STORAGE_KEY = 'learning-layout-widths-v1';
        
        let courseContext = '';
        let conversationHistory = [];

        function escapeHtml(value) {
            return String(value ?? '')
                .replace(/&/g, '&amp;')
                .replace(/</g, '&lt;')
                .replace(/>/g, '&gt;')
                .replace(/"/g, '&quot;')
                .replace(/'/g, '&#39;');
        }
        
        // ── Main Controller ──
        class LearningPageController {
            constructor() {
                this.isMac = /Mac|iPhone|iPod|iPad/i.test(navigator.platform);
                this.setupExpandables();
                this.setupQuizzes();
                this.setupProgressTracking();
                this.setupScrollReveal();
                this.setupCourseContext();
                this.setupKeyboardShortcuts();
                this.initializeMermaid();
                this.initializeCharts();
                this.updateShortcutsDisplay();
                this.setupColumnResizers();
            }
            
            initializeMermaid() {
                if (typeof mermaid !== 'undefined') {
                    mermaid.initialize({
                        startOnLoad: true,
                        theme: 'dark',
                        themeVariables: {
                            primaryColor: '#263352',
                            primaryTextColor: '#edf2f7',
                            primaryBorderColor: '#f6c177',
                            lineColor: '#a0aec0',
                            secondaryColor: '#1f2b47',
                            tertiaryColor: '#1c2a45',
                            background: '#16213e',
                            mainBkg: '#263352',
                            nodeBorder: '#f6c177',
                            clusterBkg: '#1f2b47',
                            fontSize: '14px'
                        },
                        flowchart: { curve: 'basis', padding: 20 },
                        sequence: { actorMargin: 50 }
                    });
                }
            }
            
            initializeCharts() {
                if (typeof Chart !== 'undefined') {
                    Chart.defaults.color = '#a0aec0';
                    Chart.defaults.borderColor = 'rgba(255,255,255,0.06)';
                    Chart.defaults.font.family = "-apple-system, 'Helvetica Neue', sans-serif";
                    Chart.defaults.responsive = true;
                    Chart.defaults.maintainAspectRatio = true;
                    Chart.defaults.plugins.legend.labels.usePointStyle = true;
                }
            }
            
            setupCourseContext() {
                const mc = document.querySelector('.main-content');
                if (mc) courseContext = mc.innerText.substring(0, 6000);
            }
            
            setupExpandables() {
                document.querySelectorAll('.expandable-header').forEach(header => {
                    header.addEventListener('click', () => {
                        header.parentElement.classList.toggle('open');
                    });
                });
            }
            
            setupQuizzes() {
                document.querySelectorAll('.quiz-option').forEach(opt => {
                    opt.addEventListener('click', () => this.handleQuiz(opt));
                });
            }

            handleQuiz(option) {
                const quiz = option.closest('.quiz-container');
                const isCorrect = option.dataset.correct === 'true';
                
                quiz.querySelectorAll('.quiz-option').forEach(o => {
                    o.classList.remove('selected','correct','incorrect');
                });
                
                option.classList.add('selected');
                option.classList.add(isCorrect ? 'correct' : 'incorrect');
                
                if (!isCorrect) {
                    quiz.querySelectorAll('.quiz-option').forEach(o => {
                        if (o.dataset.correct === 'true') o.classList.add('correct');
                    });
                }
                
                const cf = quiz.querySelector('.quiz-feedback.correct');
                const ic = quiz.querySelector('.quiz-feedback.incorrect');
                if (isCorrect) { cf.classList.add('show'); ic.classList.remove('show'); }
                else { ic.classList.add('show'); cf.classList.remove('show'); }
            }

            
            setupProgressTracking() {
                window.addEventListener('scroll', () => {
                    const h = document.documentElement.scrollHeight - window.innerHeight;
                    const p = h > 0 ? Math.min((window.scrollY / h) * 100, 100) : 0;
                    document.getElementById('progressBar').style.width = p + '%';
                });
            }
            
            setupScrollReveal() {
                const obs = new IntersectionObserver((entries) => {
                    entries.forEach(e => { if (e.isIntersecting) e.target.classList.add('revealed'); });
                }, { threshold: 0.08 });
                document.querySelectorAll('.reveal-on-scroll').forEach(el => obs.observe(el));
            }
            
            setupKeyboardShortcuts() {
                document.addEventListener('keydown', (e) => {
                    if (e.altKey && e.key === 'a') {
                        e.preventDefault();
                        document.getElementById('aiInput')?.focus();
                    }
                    if (e.altKey && e.key === 's') {
                        e.preventDefault();
                        askSummary();
                    }
                });
            }
            
            updateShortcutsDisplay() {
                const prefix = this.isMac ? '⌥' : 'Alt+';
                const focusEl = document.getElementById('shortcutFocusAI');
                const summaryEl = document.getElementById('shortcutSummary');
                if (focusEl) focusEl.textContent = prefix + 'A';
                if (summaryEl) summaryEl.textContent = prefix + 'S';
            }

            setupColumnResizers() {
                if (window.matchMedia('(max-width: 1200px)').matches) return;
                const container = document.querySelector('.page-container');
                const leftResizer = document.getElementById('resizerLeft');
                const rightResizer = document.getElementById('resizerRight');
                if (!container || !leftResizer || !rightResizer) return;

                const minLeft = 200, maxLeft = 560;
                const minRight = 220, maxRight = 560;
                const minMain = 520;
                let leftWidth = 260;
                let rightWidth = 300;

                const clamp = (n, min, max) => Math.max(min, Math.min(max, n));
                const applyWidths = () => {
                    container.style.setProperty('--left-width', leftWidth + 'px');
                    container.style.setProperty('--right-width', rightWidth + 'px');
                };
                const getTotalWidth = () => container.getBoundingClientRect().width - 16;
                const clampAll = () => {
                    const total = getTotalWidth();
                    leftWidth = clamp(leftWidth, minLeft, maxLeft);
                    rightWidth = clamp(rightWidth, minRight, maxRight);
                    if (total - leftWidth - rightWidth < minMain) {
                        const overflow = minMain - (total - leftWidth - rightWidth);
                        leftWidth = clamp(leftWidth - overflow / 2, minLeft, maxLeft);
                        rightWidth = clamp(rightWidth - overflow / 2, minRight, maxRight);
                        if (total - leftWidth - rightWidth < minMain) {
                            const rightCap = clamp(total - leftWidth - minMain, minRight, maxRight);
                            rightWidth = rightCap;
                            leftWidth = clamp(total - rightWidth - minMain, minLeft, maxLeft);
                        }
                    }
                };

                try {
                    const cached = JSON.parse(localStorage.getItem(LAYOUT_STORAGE_KEY) || '{}');
                    if (Number.isFinite(cached.left)) leftWidth = cached.left;
                    if (Number.isFinite(cached.right)) rightWidth = cached.right;
                } catch {}
                clampAll();
                applyWidths();

                const startDrag = (side) => (evt) => {
                    evt.preventDefault();
                    const rect = container.getBoundingClientRect();
                    const total = getTotalWidth();
                    const onMove = (moveEvt) => {
                        if (side === 'left') {
                            const rawLeft = moveEvt.clientX - rect.left;
                            const maxAllowed = Math.min(maxLeft, total - rightWidth - minMain);
                            leftWidth = clamp(rawLeft, minLeft, Math.max(minLeft, maxAllowed));
                        } else {
                            const rawRight = rect.right - moveEvt.clientX;
                            const maxAllowed = Math.min(maxRight, total - leftWidth - minMain);
                            rightWidth = clamp(rawRight, minRight, Math.max(minRight, maxAllowed));
                        }
                        applyWidths();
                    };
                    const stopMove = () => {
                        document.body.style.userSelect = '';
                        document.body.style.cursor = '';
                        leftResizer.classList.remove('dragging');
                        rightResizer.classList.remove('dragging');
                        localStorage.setItem(LAYOUT_STORAGE_KEY, JSON.stringify({ left: leftWidth, right: rightWidth }));
                        document.removeEventListener('pointermove', onMove);
                        document.removeEventListener('pointerup', stopMove);
                    };
                    document.body.style.userSelect = 'none';
                    document.body.style.cursor = 'col-resize';
                    (side === 'left' ? leftResizer : rightResizer).classList.add('dragging');
                    document.addEventListener('pointermove', onMove);
                    document.addEventListener('pointerup', stopMove);
                };

                leftResizer.addEventListener('pointerdown', startDrag('left'));
                rightResizer.addEventListener('pointerdown', startDrag('right'));
                window.addEventListener('resize', () => {
                    if (window.matchMedia('(max-width: 1200px)').matches) return;
                    clampAll();
                    applyWidths();
                });
            }
        }
        
        // ── AI Chat (Real Gemini API) ──
        async function sendAIMessage() {
            const input = document.getElementById('aiInput');
            const msg = input.value.trim();
            if (!msg) return;
            
            appendMsg('user', msg);
            input.value = '';
            input.disabled = true;
            
            const typingEl = appendMsg('assistant', '<span class="typing-dots"><span>.</span><span>.</span><span>.</span></span>');
            
            try {
                const answer = await callGemini(msg);
                typingEl.innerHTML = formatMd(answer);
            } catch (err) {
                const errMsg = err?.message || String(err);
                let hint = 'Check console for details.';
                if (window.location.protocol === 'file:' || errMsg.includes('Failed to fetch')) {
                    const current = window.location.pathname.split('/').pop();
                    hint = `Start local server: python3 serve.py --open html/${current} and ensure GEMINI_API_KEY exists in .env.local`;
                }
                typingEl.innerHTML = '⚠️ Error: ' + escapeHtml(errMsg) + '<br><small>' + escapeHtml(hint) + '</small>';
                console.error('Gemini API error:', err);
            } finally {
                input.disabled = false;
                input.focus();
            }
        }
        
        async function callGemini(userMessage) {
            if (window.location.protocol === 'file:') {
                throw new Error('This page is opened as file:// and cannot reach ../api/gemini');
            }

            const prompt = `You are a concise study assistant for this course.

Course content (excerpt):
${courseContext.substring(0, 3500)}

Previous conversation:
${conversationHistory.slice(-4).map(m => m.role + ': ' + m.content).join('\n')}

Student question: ${userMessage}

Instructions:
- Answer in 3-6 sentences, be direct and complete
- Always finish your sentences, never leave a thought incomplete
- Use the course content as reference
- If the question is in Chinese, answer in Chinese`;

            const res = await fetch(GEMINI_PROXY_URL, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    prompt: prompt,
                    generationConfig: { temperature: 0.7, maxOutputTokens: 1024 }
                })
            });
            
            if (!res.ok) {
                const errText = await res.text();
                throw new Error(`API ${res.status}: ${errText.substring(0, 200)}`);
            }
            
            const data = await res.json();
            const candidate = data.candidates?.[0];
            const answer = candidate?.content?.parts?.[0]?.text;
            if (!answer) throw new Error('Empty response from API');
            
            // Check if response was truncated
            if (candidate?.finishReason === 'MAX_TOKENS') {
                conversationHistory.push({ role: 'user', content: userMessage }, { role: 'assistant', content: answer });
                return answer + '...\n\n_(Response was trimmed. Ask a follow-up for more detail.)_';
            }
            
            conversationHistory.push({ role: 'user', content: userMessage }, { role: 'assistant', content: answer });
            return answer;
        }
        
        function appendMsg(role, html) {
            const container = document.getElementById('aiMessages');
            const div = document.createElement('div');
            div.className = 'ai-message ' + role;
            div.innerHTML = html;
            container.appendChild(div);
            container.scrollTop = container.scrollHeight;
            return div;
        }
        
        function formatMd(text) {
            return text
                .replace(/\*\*(.+?)\*\*/g, '<strong>$1</strong>')
                .replace(/\*(.+?)\*/g, '<em>$1</em>')
                .replace(/`(.+?)`/g, '<code style="background:var(--bg-tertiary);padding:0.1em 0.4em;border-radius:3px;font-size:0.9em;">$1</code>')
                .replace(/\n/g, '<br>');
        }
        
        function askSummary() {
            const input = document.getElementById('aiInput');
            input.value = 'Please summarize the key concepts of this lesson in bullet points.';
            sendAIMessage();
        }
        
        function reviewAllQuizzes() {
            const q = document.querySelector('.quiz-container');
            if (q) q.scrollIntoView({ behavior: 'smooth', block: 'center' });
        }
        
        function createSummary() { askSummary(); }
        
        // ── Sidebar Tabs ──
        function switchSidebarTab(tabName) {
            document.querySelectorAll('.sidebar-tab').forEach(t => t.classList.remove('active'));
            document.querySelectorAll('.sidebar-panel').forEach(p => p.style.display = 'none');
            document.querySelector(`.sidebar-tab[data-tab="${tabName}"]`)?.classList.add('active');
            const panel = document.getElementById('panel-' + tabName);
            if (panel) panel.style.display = 'block';
        }
        
        // ── Notes System ──
        const NOTES_STORAGE_KEY = 'learning-notes-' + document.title;
        const NOTES_FOCUS_KEY = NOTES_STORAGE_KEY + '-focus';
        const NOTES_ACTIVE_KEY = NOTES_STORAGE_KEY + '-active';
        const NOTES_DRAFT_KEY = NOTES_STORAGE_KEY + '-draft';
        
        function loadNotes() {
            try {
                const raw = JSON.parse(localStorage.getItem(NOTES_STORAGE_KEY) || '[]');
                if (!Array.isArray(raw)) return [];
                return raw.map((n, idx) => {
                    const idNum = Number(n?.id);
                    return {
                        id: Number.isFinite(idNum) ? idNum : -(idx + 1),
                        citation: typeof n?.citation === 'string' ? n.citation : (typeof n?.quote === 'string' ? n.quote : ''),
                        body: typeof n?.body === 'string' ? n.body : (typeof n?.text === 'string' ? n.text : (typeof n?.content === 'string' ? n.content : '')),
                        section: typeof n?.section === 'string' ? n.section : (typeof n?.title === 'string' ? n.title : ''),
                        timestamp: typeof n?.timestamp === 'string' && n.timestamp
                            ? n.timestamp
                            : (typeof n?.created_at === 'string' && n.created_at ? n.created_at : new Date().toISOString())
                    };
                });
            }
            catch { return []; }
        }
        
        function saveNotes(notes) {
            localStorage.setItem(NOTES_STORAGE_KEY, JSON.stringify(notes));
            renderNotes();
        }

        function saveDraft(text) {
            localStorage.setItem(NOTES_DRAFT_KEY, text || '');
        }

        function loadDraft() {
            return localStorage.getItem(NOTES_DRAFT_KEY) || '';
        }

        function renderDraftPreview(text) {
            const preview = document.getElementById('noteDraftPreviewContent');
            if (!preview) return;
            const clean = text || '';
            if (!clean.trim()) {
                preview.innerHTML = '<span style="color: var(--text-tertiary);">Type in the note box to preview Markdown rendering in real time.</span>';
                return;
            }
            preview.innerHTML = renderNoteMarkdown(clean);
        }

        function handleNoteInputChange(value) {
            saveDraft(value);
            renderDraftPreview(value);
        }

        function initNoteComposer() {
            const input = document.getElementById('noteInput');
            if (!input) return;
            const draft = loadDraft();
            input.value = draft;
            renderDraftPreview(draft);
            input.addEventListener('input', () => {
                handleNoteInputChange(input.value);
            });
            input.addEventListener('keydown', (e) => {
                if ((e.metaKey || e.ctrlKey) && e.key === 'Enter') {
                    e.preventDefault();
                    addFreeNote();
                }
            });
        }

        function getFocusedNoteId() {
            const value = localStorage.getItem(NOTES_FOCUS_KEY);
            return value ? Number(value) : null;
        }

        function getActiveNoteId() {
            const value = localStorage.getItem(NOTES_ACTIVE_KEY);
            return value ? Number(value) : null;
        }

        function setFocusedNoteId(id) {
            if (!id) localStorage.removeItem(NOTES_FOCUS_KEY);
            else localStorage.setItem(NOTES_FOCUS_KEY, String(id));
        }

        function setActiveNoteId(id) {
            if (!id) localStorage.removeItem(NOTES_ACTIVE_KEY);
            else localStorage.setItem(NOTES_ACTIVE_KEY, String(id));
        }

        function toggleFocusNote(id, e) {
            e?.stopPropagation();
            const focusedId = getFocusedNoteId();
            setFocusedNoteId(focusedId === id ? null : id);
            renderNotes();
        }

        function openNote(id) {
            setActiveNoteId(id);
            renderNotes();
            switchSidebarTab('notes');
        }

        function ensureNoteReader() {
            const panel = document.getElementById('panel-notes');
            const notesList = document.getElementById('notesList');
            if (!panel || !notesList) return null;
            notesList.style.maxHeight = '32vh';

            let reader = document.getElementById('noteReader');
            if (!reader) {
                reader = document.createElement('div');
                reader.id = 'noteReader';
                reader.className = 'note-reader';
                notesList.insertAdjacentElement('afterend', reader);
            }
            return reader;
        }

        function renderNoteMarkdown(text) {
            return escapeHtml(text || '')
                .replace(/\*\*(.+?)\*\*/g, '<strong>$1</strong>')
                .replace(/\*(.+?)\*/g, '<em>$1</em>')
                .replace(/`(.+?)`/g, '<code>$1</code>')
                .replace(/\n/g, '<br>');
        }

        function renderNoteReader(notes) {
            const reader = ensureNoteReader();
            if (!reader) return;
            if (notes.length === 0) {
                reader.innerHTML = '<div class="reader-title">Reader</div><div class="reader-content">No notes yet.</div>';
                return;
            }

            let activeId = getActiveNoteId();
            let active = notes.find(n => n.id === activeId);
            if (!active) {
                active = notes[0];
                setActiveNoteId(active.id);
            }
            const time = new Date(active.timestamp).toLocaleString();
            const citationHtml = active.citation ? `<div class="note-citation">${escapeHtml(active.citation)}</div>` : '';
            const activeBody = typeof active.body === 'string' ? active.body : '';
            reader.innerHTML = `
                <div class="reader-title">Reading • ${escapeHtml(active.section || 'General')} • ${time}</div>
                ${citationHtml}
                <div class="reader-content">${renderNoteMarkdown(activeBody)}</div>
            `;
        }
        
        function addNote(citation, body, section) {
            const notes = loadNotes();
            const note = {
                id: Date.now(),
                citation: citation || '',
                body: body || '',
                section: section || '',
                timestamp: new Date().toISOString()
            };
            notes.push(note);
            setActiveNoteId(note.id);
            saveNotes(notes);
            // Switch to notes tab
            switchSidebarTab('notes');
        }
        
        function addFreeNote() {
            const input = document.getElementById('noteInput');
            const text = input.value.trim();
            if (!text) return;
            addNote('', text, '');
            input.value = '';
            saveDraft('');
            renderDraftPreview('');
        }
        
        function deleteNote(id, e) {
            e?.stopPropagation();
            const notes = loadNotes().filter(n => n.id !== id);
            if (getFocusedNoteId() === id) setFocusedNoteId(null);
            if (getActiveNoteId() === id) setActiveNoteId(notes.length ? notes[0].id : null);
            saveNotes(notes);
        }
        
        function renderNotes() {
            const notes = loadNotes();
            const container = document.getElementById('notesList');
            const counter = document.getElementById('notesCount');
            if (!container) return;
            
            counter.textContent = notes.length + ' note' + (notes.length !== 1 ? 's' : '');
            
            if (notes.length === 0) {
                container.innerHTML = '<p style="font-size:0.85rem; color:var(--text-tertiary); text-align:center; padding:2rem 0;">Select text and click "Add Note" to begin, or write freely below.</p>';
                renderNoteReader(notes);
                return;
            }

            const focusedId = getFocusedNoteId();
            const activeId = getActiveNoteId();
            const sortedNotes = [...notes].sort((a, b) => {
                const aFocused = a.id === focusedId ? 1 : 0;
                const bFocused = b.id === focusedId ? 1 : 0;
                if (aFocused !== bFocused) return bFocused - aFocused;
                return new Date(b.timestamp) - new Date(a.timestamp);
            });

            container.innerHTML = sortedNotes.map(n => {
                const time = new Date(n.timestamp).toLocaleString();
                const citationHtml = n.citation 
                    ? `<div class="note-citation">${escapeHtml(n.citation)}</div>` 
                    : '';
                const noteBody = typeof n.body === 'string' ? n.body : '';
                const preview = noteBody.length > 140 ? (noteBody.slice(0, 140) + '...') : noteBody;
                const focusLabel = n.id === focusedId ? 'Unfocus' : 'Focus';
                return `<div class="note-card ${n.id === activeId ? 'active' : ''} ${n.id === focusedId ? 'focused' : ''}" onclick="openNote(${n.id})">
                    ${citationHtml}
                    <div class="note-body">${escapeHtml(preview)}</div>
                    <div class="note-meta">
                        <span>${n.section ? escapeHtml(n.section) : ''} ${time}</span>
                        <span>
                            <button class="note-focus" onclick="toggleFocusNote(${n.id}, event)">${focusLabel}</button>
                            <button class="note-delete" onclick="deleteNote(${n.id}, event)">Delete</button>
                        </span>
                    </div>
                </div>`;
            }).join('');
            renderNoteReader(sortedNotes);
        }
        
        function exportNotesToObsidian() {
            const notes = loadNotes();
            if (notes.length === 0) { alert('No notes to export.'); return; }
            
            const title = document.title.replace(' - Interactive Learning', '');
            const sourceFile = document.querySelector('.main-content header p')?.textContent?.match(/Source: (.+)/)?.[1] || '';
            
            let md = `---
tags: [lecture-notes, mfin7034]
source: "${sourceFile}"
date: ${new Date().toISOString().split('T')[0]}
---

`;
            md += `# ${title}

`;
            md += `> [!info] Source
> PDF: [[${sourceFile.replace('.pdf','')}]]

`;
            
            notes.forEach((n, idx) => {
                if (n.citation) {
                    md += `> [!quote] Highlight
> ${n.citation}

`;
                }
                const noteBody = typeof n.body === 'string' ? n.body : '';
                md += noteBody + `

`;
                if (idx < notes.length - 1) md += `---

`;
            });
            
            md += `
## References

- Source: ${sourceFile}
- Generated: ${new Date().toLocaleString()}
`;
            
            const blob = new Blob([md], { type: 'text/markdown;charset=utf-8' });
            const a = document.createElement('a');
            a.href = URL.createObjectURL(blob);
            a.download = title.replace(/[^a-zA-Z0-9一-鿿 ]/g, '_') + '.md';
            a.click();
            URL.revokeObjectURL(a.href);
        }
        
        // ── Text Highlight & Selection ──
        const highlightTooltip = document.createElement('div');
        highlightTooltip.className = 'highlight-tooltip';
        highlightTooltip.innerHTML = `
            <button onclick="highlightSelection()">Highlight</button>
            <button onclick="highlightAndNote()">+ Note</button>
        `;
        document.body.appendChild(highlightTooltip);
        
        document.addEventListener('mouseup', (e) => {
            const sel = window.getSelection();
            const text = sel.toString().trim();
            
            // Only show for selections within main content
            const main = document.querySelector('.main-content');
            if (!text || text.length < 3 || !main?.contains(sel.anchorNode)) {
                highlightTooltip.classList.remove('show');
                return;
            }
            
            const range = sel.getRangeAt(0);
            const rect = range.getBoundingClientRect();
            highlightTooltip.style.left = rect.left + (rect.width / 2) - 60 + 'px';
            highlightTooltip.style.top = rect.top - 40 + window.scrollY + 'px';
            highlightTooltip.classList.add('show');
        });
        
        document.addEventListener('mousedown', (e) => {
            if (!highlightTooltip.contains(e.target)) {
                highlightTooltip.classList.remove('show');
            }
        });
        
        function highlightSelection() {
            const sel = window.getSelection();
            if (!sel.rangeCount) return;
            const range = sel.getRangeAt(0);
            const mark = document.createElement('mark');
            mark.className = 'text-highlight';
            try {
                range.surroundContents(mark);
            } catch(e) {
                // Cross-element selection: fall back
                const text = sel.toString();
                mark.textContent = text;
                range.deleteContents();
                range.insertNode(mark);
            }
            sel.removeAllRanges();
            highlightTooltip.classList.remove('show');
        }
        
        function highlightAndNote() {
            const sel = window.getSelection();
            const text = sel.toString().trim();
            if (!text) return;
            
            // Find section context
            let section = '';
            let node = sel.anchorNode;
            while (node && node !== document.body) {
                if (node.classList?.contains('concept-section')) {
                    const h2 = node.querySelector('h2');
                    if (h2) section = h2.textContent;
                    break;
                }
                node = node.parentNode;
            }
            
            highlightSelection();
            
            openInlineSelectionNoteEditor(text, section, sel.getRangeAt(0).getBoundingClientRect());
        }
        

        function closeInlineSelectionNoteEditor() {
            document.getElementById('inlineSelectionNoteEditor')?.remove();
        }

        function openInlineSelectionNoteEditor(selectionText, section, rect) {
            closeInlineSelectionNoteEditor();
            const editor = document.createElement('div');
            editor.id = 'inlineSelectionNoteEditor';
            editor.style.position = 'absolute';
            editor.style.zIndex = '10030';
            editor.style.width = 'min(420px, 90vw)';
            editor.style.background = 'var(--bg-card)';
            editor.style.border = '1px solid var(--border-color)';
            editor.style.borderRadius = '12px';
            editor.style.boxShadow = '0 16px 36px rgba(0,0,0,0.32)';
            editor.style.padding = '0.65rem';
            editor.style.top = (window.scrollY + rect.bottom + 10) + 'px';
            editor.style.left = Math.max(12, Math.min(window.scrollX + rect.left, window.scrollX + window.innerWidth - 440)) + 'px';
            editor.innerHTML = `
                <div style="font-size:0.78rem;color:var(--text-tertiary);margin-bottom:0.4rem;">Add note for selection</div>
                <textarea id="inlineSelectionNoteInput" placeholder="Write note... (Markdown supported)" style="width:100%;min-height:88px;background:var(--bg-primary);color:var(--text-primary);border:1px solid var(--border-color);border-radius:8px;padding:0.5rem;font-size:0.86rem;resize:vertical;"></textarea>
                <div style="display:flex;justify-content:flex-end;gap:0.45rem;margin-top:0.45rem;">
                    <button type="button" id="inlineSelectionNoteCancel" style="border:1px solid var(--border-color);background:var(--bg-elevated);color:var(--text-primary);border-radius:8px;padding:0.3rem 0.6rem;cursor:pointer;font-size:0.8rem;">Cancel</button>
                    <button type="button" id="inlineSelectionNoteSave" style="border:1px solid rgba(163,217,165,.55);background:var(--bg-elevated);color:var(--accent-secondary);border-radius:8px;padding:0.3rem 0.6rem;cursor:pointer;font-size:0.8rem;">Save</button>
                </div>
            `;
            document.body.appendChild(editor);
            const input = editor.querySelector('#inlineSelectionNoteInput');
            input?.focus();
            editor.querySelector('#inlineSelectionNoteCancel')?.addEventListener('click', closeInlineSelectionNoteEditor);
            editor.querySelector('#inlineSelectionNoteSave')?.addEventListener('click', () => {
                const body = (input?.value || '').trim() || '(highlighted)';
                addNote(selectionText, body, section);
                closeInlineSelectionNoteEditor();
            });
        }

        // ── Init ──
        document.addEventListener('DOMContentLoaded', () => {
            new LearningPageController();
            
            // Add reveal animation to concept sections
            document.querySelectorAll('.feynman-block, .quiz-container, .expandable, .chart-container, .diagram-container, .comparison-block, .stats-grid').forEach(el => {
                el.classList.add('reveal-on-scroll');
            });
            
            // Re-init observer for dynamically added elements
            const obs = new IntersectionObserver((entries) => {
                entries.forEach(e => { if (e.isIntersecting) e.target.classList.add('revealed'); });
            }, { threshold: 0.08 });
            document.querySelectorAll('.reveal-on-scroll').forEach(el => obs.observe(el));
            
            // Initialize note draft autosave + live markdown preview
            initNoteComposer();
            // Load saved notes
            renderNotes();
        });
        
        // Typing dots animation
        const typingStyle = document.createElement('style');
        typingStyle.textContent = `
            .typing-dots span {
                animation: blink 1.4s infinite;
                font-size: 1.5em;
                line-height: 1;
            }
            .typing-dots span:nth-child(2) { animation-delay: 0.2s; }
            .typing-dots span:nth-child(3) { animation-delay: 0.4s; }
            @keyframes blink {
                0%, 60%, 100% { opacity: 0.2; }
                30% { opacity: 1; }
            }
        `;
        document.head.appendChild(typingStyle);
    
    </script>
    
    <!-- KaTeX auto-render -->
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            if (typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: "$$", right: "$$", display: true},
                        {left: "$", right: "$", display: false},
                        {left: "\\(", right: "\\)", display: false},
                        {left: "\\[", right: "\\]", display: true}
                    ],
                    throwOnError: false
                });
            }
        });
    </script>
    <script src="./app-shell.js?v=10"></script>
    <script src="./lecture-enhancements.js?v=4"></script>
</body>
</html>